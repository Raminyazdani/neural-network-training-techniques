Ramin Yazdani | Neural Network Training Techniques | main | WIP(training): Add training loop with SGD optimizer and cross-entropy loss

Implemented complete training infrastructure including epoch loop, SGD optimizer with
learning rate 0.001, CrossEntropyLoss, and per-epoch loss and accuracy tracking with
device configuration for CPU/GPU support.

With the model defined and instantiated, the training infrastructure is needed to
actually train the network. The training loop is implemented before evaluation to
establish the training process. This follows standard PyTorch training patterns with
proper device handling and metric tracking.

Changes:
- Implemented training function with epoch loop
- Added SGD optimizer with learning rate 0.001
- Configured CrossEntropyLoss
- Added per-epoch loss and accuracy tracking
- Set device configuration (CPU/GPU)

Files: 4 (notebook updated with training loop)
